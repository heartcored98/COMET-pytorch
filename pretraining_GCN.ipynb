{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from dataloader import *\n",
    "\n",
    "%matplotlib inline\n",
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_attn_head, dropout=0.1):\n",
    "        super(Attention, self).__init__()   \n",
    "\n",
    "        self.num_attn_heads = num_attn_head\n",
    "        self.attn_dim = output_dim // num_attn_head\n",
    "        self.projection = nn.ModuleList([nn.Linear(input_dim, self.attn_dim) for i in range(self.num_attn_heads)])\n",
    "        self.coef_matrix = nn.ParameterList([nn.Parameter(torch.FloatTensor(self.attn_dim, self.attn_dim)) for i in range(self.num_attn_heads)])\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.param_initializer()\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        list_X_head = list()\n",
    "        for i in range(self.num_attn_heads):\n",
    "            X_projected = self.projection[i](X)\n",
    "            attn_matrix = self.attn_coeff(X_projected, A, self.coef_matrix[i])\n",
    "            X_head = torch.matmul(attn_matrix, X_projected)\n",
    "            list_X_head.append(X_head)\n",
    "            \n",
    "        X = torch.cat(list_X_head, dim=2)\n",
    "        X = self.relu(X)\n",
    "        return X\n",
    "            \n",
    "    def attn_coeff(self, X_projected, A, C):\n",
    "        X = torch.einsum('akj,ij->aki', (X_projected, C))\n",
    "        attn_matrix = torch.matmul(X, torch.transpose(X_projected, 1, 2)) \n",
    "        attn_matrix = torch.mul(A, attn_matrix)\n",
    "        attn_matrix = self.dropout(self.tanh(attn_matrix))\n",
    "        return attn_matrix\n",
    "    \n",
    "    def param_initializer(self):\n",
    "        for i in range(self.num_attn_heads):    \n",
    "            nn.init.xavier_normal_(self.projection[i].weight.data)\n",
    "            nn.init.xavier_normal_(self.coef_matrix[i].data)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gconv, Readout, BN1D, ResBlock, Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, attn):\n",
    "        super(GConv, self).__init__()\n",
    "        self.attn = attn\n",
    "        if self.attn is None:\n",
    "            self.fc = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, X, A):\n",
    "        if self.attn is None:\n",
    "            x = self.fc(X)\n",
    "            x = torch.matmul(A, x)\n",
    "        else:\n",
    "            x = self.attn(X, A)            \n",
    "        return x, A\n",
    "    \n",
    "    \n",
    "class Readout(nn.Module):\n",
    "    def __init__(self, out_dim, molvec_dim):\n",
    "        super(Readout, self).__init__()\n",
    "        self.readout_fc = nn.Linear(out_dim, molvec_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, output_H):\n",
    "        molvec = self.readout_fc(output_H)\n",
    "        molvec = self.relu(torch.sum(molvec, dim=1))\n",
    "        return molvec\n",
    "\n",
    "class BN1d(nn.Module):\n",
    "    def __init__(self, out_dim, use_bn):\n",
    "        super(BN1d, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "             \n",
    "    def forward(self, x): \n",
    "        if not self.use_bn:\n",
    "            return  x\n",
    "        origin_shape = x.shape\n",
    "        x = x.view(-1, origin_shape[-1])\n",
    "        x = self.bn(x)\n",
    "        x = x.view(origin_shape)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, use_bn, use_attn, dp_rate, sc_type, n_attn_head=None):\n",
    "        super(ResBlock, self).__init__()   \n",
    "        self.use_bn = use_bn\n",
    "        self.sc_type = sc_type\n",
    "        \n",
    "        attn = Attention(in_dim, out_dim, n_attn_head) if use_attn else None\n",
    "        self.gconv = GConv(in_dim, out_dim, attn)\n",
    "        \n",
    "        self.bn1 = BN1d(out_dim, use_bn)\n",
    "        self.dropout = nn.Dropout2d(p=dp_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if not self.sc_type in ['no', 'gsc', 'sc']:\n",
    "            raise Exception\n",
    "\n",
    "        if self.sc_type != 'no':\n",
    "            self.bn2 = BN1d(out_dim, use_bn)\n",
    "            self.shortcut = nn.Sequential()\n",
    "            if in_dim != out_dim:\n",
    "                self.shortcut.add_module('shortcut', nn.Linear(in_dim, out_dim, bias=False))\n",
    "                \n",
    "        if self.sc_type == 'gsc':\n",
    "            self.g_fc1 = nn.Linear(out_dim, out_dim, bias=True)\n",
    "            self.g_fc2 = nn.Linear(out_dim, out_dim, bias=True)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X, A):     \n",
    "        x, A = self.gconv(X, A)\n",
    "\n",
    "        if self.sc_type == 'no': #no skip-connection\n",
    "            x = self.relu(self.bn1(x))\n",
    "            return self.dropout(x), A\n",
    "        \n",
    "        elif self.sc_type == 'sc': # basic skip-connection\n",
    "            x = self.relu(self.bn1(x))\n",
    "            x = x + self.shortcut(X)          \n",
    "            return self.dropout(self.relu(self.bn2(x))), A\n",
    "        \n",
    "        elif self.sc_type == 'gsc': # gated skip-connection\n",
    "            x = self.relu(self.bn1(x)) \n",
    "            x1 = self.g_fc1(self.shortcut(X))\n",
    "            x2 = self.g_fc2(x)\n",
    "            gate_coef = self.sigmoid(x1+x2)\n",
    "            x = torch.mul(x1, gate_coef) + torch.mul(x2, 1.0-gate_coef)\n",
    "            return self.dropout(self.relu(self.bn2(x))), A\n",
    "        \n",
    "    \n",
    "        \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.bs = args.batch_size\n",
    "        self.molvec_dim = args.molvec_dim\n",
    "        self.embedding = self.create_emb_layer(args.vocab_size, args.emb_train) \n",
    "        self.out_dim = args.out_dim\n",
    "        \n",
    "        list_gconvs = nn.ModuleList()\n",
    "        for i in range(args.num_layers):\n",
    "            if i==0:\n",
    "                list_gconvs.append(ResBlock(args.in_dim, self.out_dim, args.use_bn, args.use_attn, args.dp_rate, args.sc_type, args.n_attn_heads))\n",
    "            else:\n",
    "                list_gconvs.append(ResBlock(self.out_dim, self.out_dim, args.use_bn, args.use_attn, args.dp_rate, args.sc_type, args.n_attn_heads))\n",
    "                \n",
    "        self.gconvs = list_gconvs\n",
    "        \n",
    "        self.readout = Readout(self.out_dim, self.molvec_dim)\n",
    "    \n",
    "    def forward(self, input_X, A):   \n",
    "        x, A, molvec = self.encoder(input_X, A)\n",
    "        return x, A, molvec\n",
    "     \n",
    "    def encoder(self, input_X, A):\n",
    "        x = self._embed(input_X)\n",
    "        for i, module in enumerate(self.gconvs):\n",
    "            x, A = module(x, A)\n",
    "        molvec = self.readout(x)\n",
    "        return x, A, molvec\n",
    "    \n",
    "    def _embed(self, x):\n",
    "        embed_x = self.embedding(x[:,:,0])\n",
    "        x = torch.cat((embed_x.float(), x[:,:,1:].float()), 2)\n",
    "        return x \n",
    "\n",
    "    def create_emb_layer(self, vocab_size, emb_train=False):\n",
    "        emb_layer = nn.Embedding(vocab_size, vocab_size)\n",
    "        weight_matrix = torch.zeros((vocab_size, vocab_size))\n",
    "        for i in range(vocab_size):\n",
    "            weight_matrix[i][i] = 1\n",
    "        emb_layer.load_state_dict({'weight': weight_matrix})\n",
    "\n",
    "        if not emb_train:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "        return emb_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred_x, ground_x, vocab_size):\n",
    "    batch_size = ground_x.shape[0]\n",
    "    num_masking = ground_x.shape[1]\n",
    "    ground_x = ground_x.view(batch_size * num_masking, -1)\n",
    "    \n",
    "    symbol_loss = F.cross_entropy(pred_x[:,:vocab_size], ground_x[:, 0].detach())\n",
    "    degree_loss = F.cross_entropy(pred_x[:,vocab_size:vocab_size+6], ground_x[:,1:7].detach().max(dim=1)[1])\n",
    "    numH_loss = F.cross_entropy(pred_x[:,vocab_size+6:vocab_size+11], ground_x[:, 7:12].detach().max(dim=1)[1])\n",
    "    valence_loss = F.cross_entropy(pred_x[:,vocab_size+11:vocab_size+17], ground_x[:,12:18].detach().max(dim=1)[1])\n",
    "    isarom_loss = F.binary_cross_entropy(torch.sigmoid(pred_x[:,-1]), ground_x[:,-1].detach().float())\n",
    "    total_loss = symbol_loss + degree_loss + numH_loss + valence_loss + isarom_loss\n",
    "    return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier & Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, molvec_dim, vocab_size, dropout_rate=0):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.molvec_dim = molvec_dim\n",
    "        self.vs = vocab_size\n",
    "    \n",
    "        self.fc1 = nn.Linear(self.molvec_dim + self.out_dim, args.in_dim)\n",
    "        self.fc2 = nn.Linear(self.in_dim, args.in_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.param_initializer()\n",
    "        \n",
    "    def forward(self, X, molvec, idx_M):\n",
    "        batch_size = X.shape[0]\n",
    "        #print('idx_M', idx_M.shape)\n",
    "        num_masking = idx_M.shape[1]\n",
    "        probs_atom = list()\n",
    "        probs_degree = list()\n",
    "        probs_numH = list()\n",
    "        probs_valence = list()\n",
    "        probs_isarom = list()\n",
    "        \n",
    "        molvec = torch.unsqueeze(molvec, 1)\n",
    "        molvec = molvec.expand(batch_size, num_masking, molvec.shape[-1])\n",
    "        \n",
    "        list_concat_x = list()\n",
    "        for i in range(batch_size):\n",
    "            target_x = torch.index_select(X[i], 0, idx_M[i])\n",
    "            concat_x = torch.cat((target_x, molvec[i]), dim=1)\n",
    "            list_concat_x.append(concat_x)\n",
    "            \n",
    "        concat_x = torch.stack(list_concat_x)\n",
    "        pred_x = self.classify(concat_x)\n",
    "        pred_x = pred_x.view(batch_size * num_masking, -1)\n",
    "        return pred_x\n",
    "    \n",
    "    def classify(self, concat_x):\n",
    "        x = self.relu(self.fc1(concat_x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def param_initializer(self):\n",
    "        nn.init.xavier_normal_(self.fc1.weight.data)\n",
    "        nn.init.xavier_normal_(self.fc2.weight.data)\n",
    "    \n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self, molvec_dim, dropout_rate):\n",
    "        super(Regressor, self).__init__()\n",
    "\n",
    "        self.molvec_dim = molvec_dim\n",
    "        self.reg_fc1 = nn.Linear(self.molvec_dim, self.molvec_dim//2)\n",
    "        self.reg_fc2 = nn.Linear(self.molvec_dim//2, 1)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, molvec):\n",
    "        x = self.relu(self.reg_fc1(molvec))\n",
    "        x = self.reg_fc2(x)\n",
    "        return torch.squeeze(x)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, dataloader, optimizer, args):\n",
    "    t = time.time()\n",
    "    list_train_loss = list()\n",
    "    cnt_iter = 0\n",
    "    reg_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        epoch_train_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader['train']):\n",
    "            \n",
    "            # Setting Train Mode\n",
    "            for _, model in models.items():\n",
    "                model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get Batch Sample from DataLoader\n",
    "            input_X, A, mol_prop, ground_X, idx_M = batch\n",
    "            input_X = Variable(torch.from_numpy(input_X)).to(args.device).long()\n",
    "            A = Variable(torch.from_numpy(A)).to(args.device).float()\n",
    "            mol_prop = Variable(torch.from_numpy(mol_prop)).to(args.device).float()\n",
    "            logp, mr, tpsa = mol_prop[:,0], mol_prop[:,1], mol_prop[:,2]\n",
    "            ground_X = Variable(torch.from_numpy(ground_X)).to(args.device).long()\n",
    "            idx_M = Variable(torch.from_numpy(idx_M)).to(args.device).long()\n",
    "\n",
    "            # Encoding Molecule\n",
    "            X, A, molvec = models['encoder'](input_X, A)\n",
    "            pred_mask = models['classifier'](X, molvec, idx_M)\n",
    "\n",
    "            # Compute Mask Task Loss & Property Regression Loss\n",
    "            mask_loss = compute_loss(pred_mask, ground_X, args.vocab_size)\n",
    "            loss = mask_loss\n",
    "\n",
    "            if args.train_logp:\n",
    "                pred_logp = models['logP'](molvec)\n",
    "                logP_loss = reg_loss(pred_logp, logp)\n",
    "                loss += logP_loss\n",
    "            if args.train_mr:\n",
    "                pred_mr = models['mr'](molvec)\n",
    "                mr_loss = reg_loss(pred_mr, mr)\n",
    "                loss += mr_loss\n",
    "            if args.train_tpsa:\n",
    "                pred_tpsa = models['tpsa'](molvec)\n",
    "                tpsa_loss = reg_loss(pred_tpsa, tpsa)\n",
    "                loss += tpsa_loss\n",
    "\n",
    "            train_writer.add_scalar('loss/total', loss, cnt_iter)\n",
    "            train_writer.add_scalar('loss/mask', mask_loss, cnt_iter)\n",
    "            train_writer.add_scalar('auxilary/logP', logP_loss, cnt_iter)\n",
    "            train_writer.add_scalar('auxilary/mr', mr_loss, cnt_iter)\n",
    "            train_writer.add_scalar('auxilary/tpsa', tpsa_loss, cnt_iter)\n",
    "\n",
    "\n",
    "            epoch_train_loss += loss / len(batch)\n",
    "            list_train_loss.append({'epoch':batch_idx/len(dataloader['train'])+epoch, 'train_loss':loss})\n",
    "            \n",
    "            # Backprogating and Updating Parameter\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cnt_iter += 1   \n",
    "\n",
    "            # Save Model \n",
    "            if cnt_iter % args.save_every:\n",
    "                pass # save model status\n",
    "\n",
    "            # Validate Model\n",
    "            if cnt_iter % args.validate_every == 0:\n",
    "                optimizer.zero_grad()\n",
    "                validate(models, dataloader['val'], args, cnt_iter=cnt_iter)\n",
    "                \n",
    "            # Prompting Status\n",
    "            if cnt_iter % args.log_every == 0:\n",
    "                print(time.time()-t, loss)\n",
    "            t = time.time()\n",
    "\n",
    "    return models, list_train_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, model_name, epoch):\n",
    "    filename= '{}_{}_ckpt.pth'.format(model_name, epoch)\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "\n",
    "def experiment(dataloader, args):\n",
    "    ts = time.time()\n",
    "    \n",
    "    # Construct Model\n",
    "    encoder = Encoder(args)\n",
    "    classifier = Classifier(args.in_dim, args.out_dim, args.molvec_dim, args.vocab_size, args.dp_rate)\n",
    "    models = {'encoder': encoder, 'classifier': classifier}\n",
    "    if args.train_logp:\n",
    "        models.update({'logP': Regressor(args.molvec_dim, args.dp_rate)})\n",
    "    if args.train_mr:\n",
    "        models.update({'mr': Regressor(args.molvec_dim, args.dp_rate)})\n",
    "    if args.train_tpsa:\n",
    "        models.update({'tpsa': Regressor(args.molvec_dim, args.dp_rate)})\n",
    "    \n",
    "    # Initialize Optimizer\n",
    "    trainable_parameters = list()\n",
    "    for key, model in models.items():\n",
    "        model.to(args.device)\n",
    "        trainable_parameters += list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "        print(key, sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "    \n",
    "    if args.optim == 'ADAM':\n",
    "        optimizer = optim.Adam(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'RMSProp':\n",
    "        optimizer = optim.RMSprop(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    elif args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(trainable_parameters, lr=args.lr, weight_decay=args.l2_coef)\n",
    "    else:\n",
    "        assert False, \"Undefined Optimizer Type\"\n",
    "        \n",
    "    # Initialize Data Logger\n",
    "    list_train_loss = list()\n",
    "    list_val_loss = list()\n",
    "    list_logp_mae = list()\n",
    "    list_logp_std = list()\n",
    "    list_mr_mae = list()\n",
    "    list_mr_std = list()\n",
    "    list_tpsa_mae = list()\n",
    "    list_tpsa_std = list()\n",
    "    \n",
    "    tot_iter = 0\n",
    "    args.best_mae = 10000\n",
    "    \n",
    "    # Train Model\n",
    "    train(models, dataloader, optimizer, args)\n",
    "\n",
    "    list_train_loss += train_losses\n",
    "    list_val_loss.append({'epoch':epoch, 'val_loss':val_loss})\n",
    "    list_logp_mae.append({'epoch':epoch, 'mae':logp_mae})\n",
    "    list_logp_std.append({'epoch':epoch, 'std':logp_std})\n",
    "    list_mr_mae.append({'epoch':epoch, 'mae':logp_mae})\n",
    "    list_mr_std.append({'epoch':epoch, 'std':logp_std})\n",
    "    list_tpsa_mae.append({'epoch':epoch, 'mae':tpsa_mae})\n",
    "    list_tpsa_std.append({'epoch':epoch, 'std':tpsa_std})\n",
    "\n",
    "    if args.best_mae > mae or epoch==0:\n",
    "        args.best_epoch = epoch\n",
    "        args.best_mae = mae\n",
    "        args.best_std = std\n",
    "        #args.best_true_y = true_y\n",
    "        #args.best_pred_y = pred_y\n",
    "\n",
    "    if total_iter % args.save_every == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'encoder': models['encoder'],\n",
    "            'encoder_state_dict': models['encoder'].state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "             })\n",
    "\n",
    "    total_iter += 1\n",
    "\n",
    "          \n",
    "    te = time.time()\n",
    "    \n",
    "    # Logging Experiment Results\n",
    "    args.elapsed = te-ts\n",
    "    args.train_losses = list_train_loss\n",
    "    args.val_losses = list_val_loss\n",
    "    args.logp_maes = list_logp_mae\n",
    "    args.logp_stds = list_logp_std\n",
    "    args.tpsa_maes = list_tpsa_mae\n",
    "    args.tpsa_stds = list_tpsa_std\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import datetime\n",
    "\n",
    "def make_model_comment(args, prior_keyword=['num_layers', 'out_dim', \n",
    "                                       'molvec_dim', 'sc_type',\n",
    "                                       'use_attn', 'n_attn_heads',\n",
    "                                       'use_bn', 'emb_train', \n",
    "                                       'train_logp', 'train_mr', \n",
    "                                       'train_tpsa', 'optim', \n",
    "                                       'lr', 'l2_coef', \n",
    "                                       'dp_rate', 'batch_size',\n",
    "                                        'train_logp', 'train_mr', 'train_tpsa']):\n",
    "    model_name = datetime.datetime.now().strftime('%y-%m-%d_%H:%M:%S') + \"_\"\n",
    "    dict_args = vars(args)\n",
    "    if 'bar' in dict_args:\n",
    "        del dict_args['bar']\n",
    "    for keyword in prior_keyword:\n",
    "        value = str(dict_args[keyword])\n",
    "        if value.isdigit():\n",
    "            try:\n",
    "                value = int(value)\n",
    "                model_name += keyword + ':{}_'.format(dict_args[keyword])\n",
    "            except:\n",
    "                model_name += keyword + ':{:.2E}_'.format(Decimal(dict_args[keyword]))\n",
    "        else:\n",
    "            model_name += keyword + ':{}_'.format(value)\n",
    "    return model_name[:254]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "##### SIZE #####\n",
    "args.vocab_size = 41\n",
    "args.in_dim = 59\n",
    "args.out_dim = 512\n",
    "args.molvec_dim = 512\n",
    "\n",
    "\n",
    "##### MODEL #####\n",
    "args.num_layers = 8\n",
    "args.use_attn = True\n",
    "args.n_attn_heads = 8\n",
    "args.use_bn = True\n",
    "args.sc_type = 'sc'\n",
    "args.emb_train = True\n",
    "args.train_logp = True\n",
    "args.train_mr = True\n",
    "args.train_tpsa = True\n",
    "\n",
    "##### HYPERPARAMETERS #####\n",
    "args.optim = 'ADAM'\n",
    "args.lr = 0.001\n",
    "args.l2_coef = 0.001\n",
    "args.dp_rate = 0.1\n",
    "\n",
    "##### EXP #####\n",
    "args.epoch = 100\n",
    "args.batch_size = 512\n",
    "args.test_batch_size = 512\n",
    "args.save_every = 50\n",
    "args.validate_every = 10\n",
    "args.log_every = 5\n",
    "\n",
    "##### DEVICE #####\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "##### LOGGING #####\n",
    "args.log_path = 'runs'\n",
    "args.model_explain = make_model_comment(args)\n",
    "args.model_name = 'exp_test1'\n",
    "train_writer = SummaryWriter(join(args.log_path, args.model_name+'_train'))\n",
    "val_writer = SummaryWriter(join(args.log_path, args.model_name+'_val'))\n",
    "logger = get_logger(join(args.log_path, args.model_name+'_train'))\n",
    "train_writer.add_text(tag='model', text_string='{}:{}'.format(args.model_name, args.model_explain), global_step= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_logger(log_path, filename='train.log', logger_name=None):\n",
    "\n",
    "    # Init\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    fh = logging.FileHandler(join(log_path, 'train.log'))\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fh.setFormatter(formatter)\n",
    "    ch.setFormatter(formatter)\n",
    "    # add the handlers to the logger\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "train_dataset_path = './dataset/processed_zinc_smiles/data_xs/train'\n",
    "val_dataset_path = './dataset/processed_zinc_smiles/data_xs/val'\n",
    "\n",
    "list_trains = get_dir_files(train_dataset_path)\n",
    "list_vals = get_dir_files(val_dataset_path)\n",
    "\n",
    "train_dataloader = zincDataLoader(join(train_dataset_path, list_trains[0]),\n",
    "                                  batch_size=args.batch_size,\n",
    "                                  drop_last=False,\n",
    "                                  shuffle_batch=True,\n",
    "                                  num_workers=8)\n",
    "\n",
    "val_dataloader = zincDataLoader(join(val_dataset_path, list_vals[0]),\n",
    "                                  batch_size=args.test_batch_size,\n",
    "                                  drop_last=False,\n",
    "                                  shuffle_batch=False,\n",
    "                                  num_workers=8)\n",
    "\n",
    "dataloader = {'train': train_dataloader, 'val': val_dataloader}\n",
    "print(len(train_dataloader))              \n",
    "print(len(val_dataloader))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(models, data_loader, args, **kwargs):\n",
    "\n",
    "    t = time.time()\n",
    "    epoch_val_loss = 0\n",
    "    cnt_iter = kwargs['cnt_iter']\n",
    "    temp_iter = 0\n",
    "    reg_loss = nn.MSELoss()\n",
    "    \n",
    "    mask_loss = []\n",
    "    logP_loss = []\n",
    "    mr_loss = []\n",
    "    tpsa_loss = []\n",
    "    \n",
    "    list_logp, list_pred_logp = [], []\n",
    "    list_mr, list_pred_mr = [], []\n",
    "    list_tpsa, list_pred_tpsa = [], []\n",
    "    logp_mae, logp_std, mr_mae, mr_std, tpsa_mae, tpsa_std = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    # Initialization Model with Evaluation Mode\n",
    "    for _, model in models.items():\n",
    "        model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            input_X, A, mol_prop, ground_X, idx_M = batch\n",
    "            input_X = Variable(torch.from_numpy(input_X)).to(args.device).long()\n",
    "            A = Variable(torch.from_numpy(A)).to(args.device).float()\n",
    "            mol_prop = Variable(torch.from_numpy(mol_prop)).to(args.device).float()\n",
    "            logp, mr, tpsa = mol_prop[:,0], mol_prop[:,1], mol_prop[:,2]\n",
    "            ground_X = Variable(torch.from_numpy(ground_X)).to(args.device).long()\n",
    "            idx_M = Variable(torch.from_numpy(idx_M)).to(args.device).long()\n",
    "\n",
    "            # Encoding Molecule\n",
    "            X, A, molvec = models['encoder'](input_X, A)\n",
    "            pred_mask = models['classifier'](X, molvec, idx_M)\n",
    "            \n",
    "            # Compute Mask Task Loss & Property Regression Loss\n",
    "            mask_loss.append(compute_loss(pred_mask, ground_X, args.vocab_size).item())\n",
    "\n",
    "            if args.train_logp:\n",
    "                pred_logp = models['logP'](molvec)\n",
    "                logP_loss.append(reg_loss(pred_logp, logp).item())\n",
    "            if args.train_mr:\n",
    "                pred_mr = models['mr'](molvec)\n",
    "                mr_loss.append(reg_loss(pred_mr, mr).item())\n",
    "            if args.train_tpsa:\n",
    "                pred_tpsa = models['tpsa'](molvec)\n",
    "                tpsa_loss.append(reg_loss(pred_tpsa, tpsa).item())\n",
    "\n",
    "            temp_iter += 1   \n",
    "            if temp_iter > 30:\n",
    "                break\n",
    "\n",
    "            if cnt_iter % args.log_every:\n",
    "                print(time.time()-t, loss)\n",
    "                t = time.time()\n",
    "    print('len', len(mask_loss))\n",
    "\n",
    "    mask_loss = np.mean(np.array(mask_loss))\n",
    "    loss = mask_loss\n",
    "    if args.train_logp:\n",
    "        logP_loss = np.mean(np.array(logP_loss))\n",
    "        loss += logP_loss\n",
    "    if args.train_mr:\n",
    "        mr_loss = np.mean(np.array(mr_loss))\n",
    "        loss += mr_loss\n",
    "    if args.train_tpsa:\n",
    "        tpsa_loss = np.mean(np.array(tpsa_loss))\n",
    "        loss += tpsa_loss\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate overall MAE and STD value      \n",
    "    if args.train_logp:\n",
    "        logp_mae = mean_absolute_error(list_logp, list_pred_logp)\n",
    "        logp_std = np.std(np.array(list_logp)-np.array(list_pred_logp))\n",
    "        \n",
    "    if args.train_mr:\n",
    "        mr_mae = mean_absolute_error(list_mr, list_pred_mr)\n",
    "        mr_std = np.std(np.array(list_mr)-np.array(list_pred_mr))\n",
    "        \n",
    "    if args.train_tpsa:\n",
    "        tpsa_mae = mean_absolute_error(list_tpsa, list_pred_tpsa)\n",
    "        tpsa_std = np.std(np.array(list_tpsa)-np.array(list_pred_tpsa))\n",
    "    \"\"\"\n",
    "        \n",
    "    val_writer.add_scalar('loss/total', loss, cnt_iter)\n",
    "    val_writer.add_scalar('loss/mask', mask_loss, cnt_iter)\n",
    "    val_writer.add_scalar('auxilary/logP', logP_loss, cnt_iter)\n",
    "    val_writer.add_scalar('auxilary/mr', mr_loss, cnt_iter)\n",
    "    val_writer.add_scalar('auxilary/tpsa', tpsa_loss, cnt_iter)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return epoch_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder 2442385\n",
      "classifier 64015\n",
      "logP 131585\n",
      "mr 131585\n",
      "tpsa 131585\n",
      "0.3260374069213867 tensor(20.1925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.556497097015381 tensor(11.7201, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3225860595703125 tensor(10.6978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.660623550415039 tensor(10.5232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.343076229095459 tensor(9.9176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7694501876831055 tensor(12.7000, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37003326416015625 tensor(8.4910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.541049242019653 tensor(7.4922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4112124443054199 tensor(6.4066, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.386129379272461 tensor(7.3410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41561317443847656 tensor(7.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.772103548049927 tensor(10.7253, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.44057178497314453 tensor(6.2257, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.783203601837158 tensor(7.1129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3983931541442871 tensor(6.8420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.244948148727417 tensor(7.0126, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.39091062545776367 tensor(7.7156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.53083348274231 tensor(8.1946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.32532596588134766 tensor(6.0578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.986388921737671 tensor(7.5118, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2827274799346924 tensor(6.9656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.768237590789795 tensor(6.0028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.38898539543151855 tensor(8.1481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8999104499816895 tensor(6.9419, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.25565075874328613 tensor(7.9925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.571499824523926 tensor(6.5770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3156306743621826 tensor(7.0702, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.431215286254883 tensor(6.8105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34299468994140625 tensor(7.7096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.657944917678833 tensor(6.9618, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4707677364349365 tensor(6.6723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.735912799835205 tensor(6.3823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.39647769927978516 tensor(7.3541, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.3031980991363525 tensor(7.3996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3286569118499756 tensor(8.3967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.596238613128662 tensor(6.7754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4312300682067871 tensor(6.3271, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.764372825622559 tensor(8.6514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4325389862060547 tensor(7.0866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.780325651168823 tensor(8.1553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34258031845092773 tensor(7.7192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.616614818572998 tensor(7.8520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3529660701751709 tensor(7.1152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.058342456817627 tensor(13.9774, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.29676032066345215 tensor(7.1221, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.030324697494507 tensor(6.0331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4304354190826416 tensor(6.1455, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.979078769683838 tensor(7.7636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2754521369934082 tensor(7.2102, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.748879909515381 tensor(6.9457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3738851547241211 tensor(6.6869, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.487555503845215 tensor(6.6691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3476576805114746 tensor(7.8244, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.716780662536621 tensor(5.5212, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3602409362792969 tensor(7.2681, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.721861124038696 tensor(6.3366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2910633087158203 tensor(7.5583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.506780385971069 tensor(6.2797, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.38377976417541504 tensor(6.6610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.788078546524048 tensor(5.6778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34621763229370117 tensor(7.8546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.389878034591675 tensor(15.7454, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.31676363945007324 tensor(7.1778, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.505738735198975 tensor(6.1817, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3606104850769043 tensor(7.4658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.509727716445923 tensor(7.0940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3186478614807129 tensor(5.6296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.838573694229126 tensor(6.2437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3303074836730957 tensor(6.9630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.571604251861572 tensor(7.8799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2610149383544922 tensor(6.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.814360618591309 tensor(5.8392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41013050079345703 tensor(5.3347, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.873993396759033 tensor(9.0638, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4193284511566162 tensor(6.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.49214243888855 tensor(7.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4727160930633545 tensor(5.8285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.81778359413147 tensor(6.3866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4355654716491699 tensor(7.6848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.475676774978638 tensor(7.8734, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.44202733039855957 tensor(5.9753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8302366733551025 tensor(7.1288, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.40506887435913086 tensor(6.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.6459667682647705 tensor(6.8456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3524589538574219 tensor(7.0121, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.358099699020386 tensor(6.6030, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3606405258178711 tensor(8.0798, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7535271644592285 tensor(6.3941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34302759170532227 tensor(6.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.674858093261719 tensor(6.0437, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3636796474456787 tensor(6.3870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.860386371612549 tensor(6.9627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4472508430480957 tensor(7.4819, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8764965534210205 tensor(7.3156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35889363288879395 tensor(6.7232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.694205045700073 tensor(7.3371, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35303568840026855 tensor(5.5468, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.748676538467407 tensor(8.9968, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.40223193168640137 tensor(5.9327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.602663516998291 tensor(6.4332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.43315601348876953 tensor(6.5867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7575836181640625 tensor(7.1217, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3428385257720947 tensor(6.8994, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.679533958435059 tensor(6.7418, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39180469512939453 tensor(5.9603, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.030574798583984 tensor(5.9865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4050450325012207 tensor(5.6696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.16102933883667 tensor(5.5780, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3760523796081543 tensor(6.9820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.771934747695923 tensor(6.8851, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.29741334915161133 tensor(7.2298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.744291067123413 tensor(7.2989, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2408440113067627 tensor(24.4954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.927241563796997 tensor(11.7462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.45587944984436035 tensor(9.2693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.812308311462402 tensor(7.2036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.42445874214172363 tensor(7.6705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.82539963722229 tensor(12.5748, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4559326171875 tensor(5.9386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.342676639556885 tensor(7.2689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.40183258056640625 tensor(6.5467, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.973439931869507 tensor(6.5738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4149317741394043 tensor(5.4157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.78983998298645 tensor(5.6696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.36916542053222656 tensor(8.1190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.726121187210083 tensor(8.7445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3920416831970215 tensor(5.9199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.525469779968262 tensor(5.9170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41027379035949707 tensor(5.6328, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.753711462020874 tensor(5.7696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3910038471221924 tensor(5.8250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.490139484405518 tensor(6.6464, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3977024555206299 tensor(5.9207, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.727442741394043 tensor(6.2120, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41782379150390625 tensor(5.6531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.463481664657593 tensor(5.3918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2486438751220703 tensor(6.5061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7490739822387695 tensor(5.9903, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.44274449348449707 tensor(6.3342, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.118182420730591 tensor(6.1410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.39516258239746094 tensor(5.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.847432374954224 tensor(5.7889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.32846927642822266 tensor(6.1971, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.6685192584991455 tensor(5.9044, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3856797218322754 tensor(4.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.881705284118652 tensor(7.1711, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3369128704071045 tensor(5.9628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9838128089904785 tensor(6.6941, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3637213706970215 tensor(5.3517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.92791748046875 tensor(4.7186, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4253408908843994 tensor(5.5531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.700981855392456 tensor(5.2402, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4237487316131592 tensor(5.5586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.816213369369507 tensor(5.0130, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37882113456726074 tensor(6.0906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.542553901672363 tensor(5.4615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3811469078063965 tensor(6.7198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.596862316131592 tensor(6.2765, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4251737594604492 tensor(5.0700, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8938374519348145 tensor(6.9632, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35363054275512695 tensor(6.2905, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.6047728061676025 tensor(6.4956, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.310089111328125 tensor(5.3752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.705308675765991 tensor(5.8754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.31846022605895996 tensor(6.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "6.452208518981934 tensor(5.1149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3545219898223877 tensor(5.9648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.774334669113159 tensor(6.0571, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33690881729125977 tensor(6.0375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.739753007888794 tensor(4.8024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33739161491394043 tensor(5.2575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.236934661865234 tensor(4.3821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4176325798034668 tensor(4.4546, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9846813678741455 tensor(4.6184, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3418240547180176 tensor(5.6054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.94625186920166 tensor(5.8429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33812904357910156 tensor(5.7369, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.955535411834717 tensor(4.7388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4378645420074463 tensor(4.2569, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.901202917098999 tensor(4.5519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35523462295532227 tensor(4.5965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.56475567817688 tensor(4.6488, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3941769599914551 tensor(4.5150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.877550363540649 tensor(4.3320, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34791040420532227 tensor(4.7897, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.68379020690918 tensor(4.4799, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41260552406311035 tensor(4.7076, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.889501094818115 tensor(4.7742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3610560894012451 tensor(4.5125, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.284661769866943 tensor(4.8482, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3516063690185547 tensor(5.8061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8853209018707275 tensor(4.9802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37158870697021484 tensor(5.5107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.555320978164673 tensor(4.8735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3464376926422119 tensor(7.0396, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.671752691268921 tensor(4.3690, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33974170684814453 tensor(4.8042, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.966858148574829 tensor(4.7611, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4210021495819092 tensor(4.7251, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.932222366333008 tensor(5.2401, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3673536777496338 tensor(3.9492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.63810920715332 tensor(5.3909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.460024356842041 tensor(4.8586, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.072439908981323 tensor(3.7613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3011293411254883 tensor(4.6979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.72239875793457 tensor(5.0220, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3244609832763672 tensor(5.4728, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.774487257003784 tensor(3.9969, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.41171717643737793 tensor(4.0110, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 31\n",
      "4.894888162612915 tensor(4.9430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3673405647277832 tensor(4.5999, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.2335731983184814 tensor(4.3800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2828559875488281 tensor(4.4997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8249897956848145 tensor(4.4415, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4370081424713135 tensor(3.6086, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.002864599227905 tensor(4.8803, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34188222885131836 tensor(4.5973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.647282361984253 tensor(4.3197, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4458324909210205 tensor(5.0123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.855892896652222 tensor(4.3754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33625102043151855 tensor(5.5465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.624566316604614 tensor(5.5537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3950352668762207 tensor(3.9339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.809915065765381 tensor(4.2718, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37344956398010254 tensor(4.4696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.596932649612427 tensor(3.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3870861530303955 tensor(5.0792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9564528465271 tensor(4.1642, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.28421711921691895 tensor(4.8972, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.899931192398071 tensor(5.9839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3738274574279785 tensor(4.0354, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.677501440048218 tensor(4.1038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3302299976348877 tensor(4.4397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.887856960296631 tensor(6.3808, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.484149694442749 tensor(4.4758, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.454456567764282 tensor(6.3834, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35492515563964844 tensor(4.2353, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.757438659667969 tensor(4.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3491477966308594 tensor(4.3692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.822349309921265 tensor(3.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4040565490722656 tensor(3.9190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.122552156448364 tensor(3.7385, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35395169258117676 tensor(4.3587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9283246994018555 tensor(4.1054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34212255477905273 tensor(3.5334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.971431493759155 tensor(4.8059, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.33615684509277344 tensor(4.9054, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.662140846252441 tensor(4.0311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.428419828414917 tensor(3.6802, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.774900197982788 tensor(3.8311, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37566614151000977 tensor(3.6457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.522009372711182 tensor(4.3088, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.34929394721984863 tensor(4.1490, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.904324293136597 tensor(3.9973, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4272420406341553 tensor(3.2942, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.95620059967041 tensor(4.7296, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4618203639984131 tensor(3.3316, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9175403118133545 tensor(3.6531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4457237720489502 tensor(3.2382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.008652925491333 tensor(4.5668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4017934799194336 tensor(3.5499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.816015720367432 tensor(3.7013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35599327087402344 tensor(3.5319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.5719451904296875 tensor(6.0677, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37674522399902344 tensor(3.8926, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.044135332107544 tensor(3.4919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.43174076080322266 tensor(3.6381, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.8707239627838135 tensor(3.3043, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.39566755294799805 tensor(3.3423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.73379921913147 tensor(3.9046, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.37891602516174316 tensor(3.3209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.149588584899902 tensor(3.3116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3767697811126709 tensor(4.2461, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7749927043914795 tensor(3.6813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.45847630500793457 tensor(5.1495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.9674811363220215 tensor(4.1760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4098491668701172 tensor(3.4070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.830538511276245 tensor(6.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.32604169845581055 tensor(3.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.05185079574585 tensor(3.8512, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3433229923248291 tensor(3.5131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.7779014110565186 tensor(4.5882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.43004846572875977 tensor(3.7860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.996074438095093 tensor(4.6058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3953831195831299 tensor(3.5746, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.839880704879761 tensor(4.0967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4401373863220215 tensor(3.6568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.3371968269348145 tensor(3.0104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.35782289505004883 tensor(3.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "5.046414375305176 tensor(3.5909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.4525909423828125 tensor(4.1614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.901559352874756 tensor(4.4057, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.3820366859436035 tensor(3.3576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "len 31\n",
      "4.706820964813232 tensor(4.2219, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "0.2921738624572754 tensor(3.9356, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-545d40d4a4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-dc8b34285745>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(dataloader, args)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mlist_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dc8b34285745>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, dataloader, optimizer, args)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcnt_iter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnt_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Prompting Status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7dd50e229fcd>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(models, data_loader, args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0minput_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minput_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/comet/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = experiment(dataloader, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (comet)",
   "language": "python",
   "name": "comet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
