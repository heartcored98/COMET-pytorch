{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from torchtext.data import RawField, Field, TabularDataset, BucketIterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rdkit import Chem\n",
    "from scipy.linalg import fractional_matrix_power\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "MASKING_RATE = 0.15\n",
    "ERASE_RATE = 0.5\n",
    "\n",
    "def get_dir_files(dir_path):\n",
    "    list_file = [f for f in os.listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "    return list_file\n",
    "\n",
    "train_dataset_path = './dataset/processed_zinc_smiles/data_xs/train'\n",
    "val_dataset_path = './dataset/processed_zinc_smiles/data_xs/val'\n",
    "\n",
    "list_trains = get_dir_files(train_dataset_path)\n",
    "\n",
    "pd.read_csv(join(train_dataset_path, list_trains[0])).head(5)\n",
    "# a.hist()\n",
    "# print(a.loc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_feature(atom):\n",
    "    return np.array(char_to_ix(atom.GetSymbol(),\n",
    "                              ['C', 'N', 'O', 'S', 'F', 'H', 'Si', 'P', 'Cl', 'Br',\n",
    "                               'Li', 'Na', 'K', 'Mg', 'Ca', 'Fe', 'As', 'Al', 'I', 'B',\n",
    "                               'V', 'Tl', 'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn',\n",
    "                               'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'Mn', 'Cr', 'Pt', 'Hg', 'Pb']) +\n",
    "                    one_of_k_encoding_unk(atom.GetDegree(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4]) +\n",
    "                    one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5]) +\n",
    "                    [atom.GetIsAromatic()])    # (40, 6, 5, 6, 1)\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def char_to_ix(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        return [0] # Unknown Atom Token\n",
    "    return [allowable_set.index(x)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zincDataset(Dataset):\n",
    "    def __init__(self, data_path, skip_header=True):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.loc[index, :]\n",
    "        smile = row.smile\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
    "        list_feature = list()\n",
    "        for atom in mol.GetAtoms():\n",
    "            list_feature.append(atom_feature(atom))\n",
    "        \n",
    "        return row.length, np.array(list_feature), adj, row.logP, row.mr, row.tpsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_onehot(size):\n",
    "    temp = np.zeros(size)\n",
    "    temp[np.random.randint(0, size)] = 1\n",
    "    return temp \n",
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Symmetry Normalization\"\"\"\n",
    "    rowsum = np.diag(np.array(mx.sum(1)))\n",
    "    r_inv = fractional_matrix_power(rowsum, -0.5)\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    return r_inv.dot(mx).dot(r_inv)\n",
    "\n",
    "def masking_feature(feature, num_masking):\n",
    "    masking_indices = np.random.choice(len(feature), num_masking, replace=False)\n",
    "    ground_truth = np.copy(feature[masking_indices, :])\n",
    "    for i in masking_indices:\n",
    "        prob_masking = np.random.rand(5)\n",
    "        # Masking Atom Symbol \n",
    "        if prob_masking[0] < ERASE_RATE:\n",
    "            feature[i, 0] = 0\n",
    "        elif prob_masking[0] > 1- ((1-ERASE_RATE) * 0.5):\n",
    "            feature[i, 0] = np.random.randint(1, 41)\n",
    "            \n",
    "        # Masking Degree \n",
    "        if prob_masking[1] < ERASE_RATE:\n",
    "            feature[i, 1:7] = np.zeros(6)\n",
    "        elif prob_masking[1] > 1- ((1-ERASE_RATE) * 0.5):\n",
    "            feature[i, 1:7] =  random_onehot(6)\n",
    "        \n",
    "        # Masking Num Hs\n",
    "        if prob_masking[2] < ERASE_RATE:\n",
    "            feature[i, 7:12] = np.zeros(5)\n",
    "        elif prob_masking[2] > 1- ((1-ERASE_RATE) * 0.5):\n",
    "            feature[i, 7:12] =  random_onehot(5)\n",
    "            \n",
    "        # Masking Valence\n",
    "        if prob_masking[3] < ERASE_RATE:\n",
    "            feature[i, 12:18] = np.zeros(6)\n",
    "        elif prob_masking[3] > 1- ((1-ERASE_RATE) * 0.5):\n",
    "            feature[i, 12:18] =  random_onehot(6)\n",
    "            \n",
    "        # Masking IsAromatic\n",
    "        if prob_masking[4] < ERASE_RATE:\n",
    "            feature[i, 18] = (feature[i, 18]+1)%2\n",
    "\n",
    "    return feature, ground_truth, masking_indices\n",
    "\n",
    "\n",
    "def postprocess_batch(mini_batch):\n",
    "    max_length = max([row[0] for row in mini_batch])\n",
    "    num_masking = int(max_length * MASKING_RATE)\n",
    "    batch_length = len(mini_batch)\n",
    "    batch_feature = np.zeros((batch_length, max_length, mini_batch[0][1].shape[1]), dtype=int)\n",
    "    batch_adj = np.zeros((batch_length, max_length, max_length))\n",
    "    batch_property = np.zeros((batch_length, 3))\n",
    "    batch_ground = np.zeros((batch_length, num_masking, mini_batch[0][1].shape[1]), dtype=int)\n",
    "    batch_masking = np.zeros((batch_length, num_masking), dtype=int)\n",
    "    \n",
    "    for i, row in enumerate(mini_batch):\n",
    "        mol_length, feature, adj = row[0], row[1], row[2]\n",
    "        masked_feature, ground_truth, masking_indices  = masking_feature(feature, num_masking)\n",
    "        batch_feature[i, :mol_length, :] = masked_feature\n",
    "        batch_ground[i, :, :] = ground_truth\n",
    "        batch_masking[i, :] = masking_indices\n",
    "        batch_adj[i, :mol_length, :mol_length] = normalize_adj(adj+np.eye(len(adj)))\n",
    "        batch_property[i, :] = [row[3], row[4], row[5]]\n",
    "        \n",
    "    return batch_feature, batch_adj, batch_property, batch_ground, batch_masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = zincDataset(data_path=join(train_dataset_path, list_trains[0]))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=1000, collate_fn=postprocess_batch, num_workers=12)\n",
    "# print(next(train_dataloader.__iter__())[3])\n",
    "for batch in train_dataloader:\n",
    "#     print(batch[0])\n",
    "    print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
